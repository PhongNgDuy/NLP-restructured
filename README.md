# NLP Labs - Natural Language Processing Projects

Repository n√†y ch·ª©a c√°c b√†i th·ª±c h√†nh v√† d·ª± √°n v·ªÅ X·ª≠ l√Ω Ng√¥n ng·ªØ T·ª± nhi√™n (NLP) ƒë∆∞·ª£c th·ª±c hi·ªán trong h·ªçc k·ª≥.

## C·∫•u tr√∫c th∆∞ m·ª•c

```
./
‚îú‚îÄ‚îÄ src/              # Ch·ª©a c√°c code nh∆∞ .py, .scala, ...
‚îú‚îÄ‚îÄ report/           # Ch·ª©a c√°c b√°o c√°o (lab1_part1.md, lab2_part2.pdf, ...)
‚îú‚îÄ‚îÄ notebook/         # Ch·ª©a c√°c notebook ƒë·ªÉ code nhanh m·ªôt ch·ªß ƒë·ªÅ
‚îú‚îÄ‚îÄ test/             # Ch·ª©a code ghi test
‚îú‚îÄ‚îÄ data/             # Ch·ª©a m√¥ t·∫£ v·ªÅ d·ªØ li·ªáu (kh√¥ng ch·ª©a dataset l·ªõn)
‚îî‚îÄ‚îÄ README.md         # File n√†y
```

## Danh s√°ch c√°c Lab

### Lab 1-2: Text Tokenization & Count Vectorization
- **M√¥ t·∫£**: Th·ª±c hi·ªán tokenization v√† vectorization c∆° b·∫£n
- **B√°o c√°o**: `report/lab1-2.md`
- **Code**: `src/preprocessing/`, `src/representations/`

### Lab 2: NLP Pipeline v·ªõi Apache Spark
- **M√¥ t·∫£**: X√¢y d·ª±ng pipeline x·ª≠ l√Ω vƒÉn b·∫£n s·ª≠ d·ª•ng Spark MLlib
- **B√°o c√°o**: `report/lab2.md`
- **Code**: `src/spark/`

### Lab 4: Word Embeddings v·ªõi Word2Vec
- **M√¥ t·∫£**: Tri·ªÉn khai word embeddings v·ªõi GloVe v√† Word2Vec
- **B√°o c√°o**: `report/lab4.md`
- **Code**: `src/representations/word_embedder.py`

### Lab 5: Ph√¢n lo·∫°i VƒÉn b·∫£n (Text Classification)
- **M√¥ t·∫£**: X√¢y d·ª±ng pipeline ph√¢n lo·∫°i vƒÉn b·∫£n v·ªõi scikit-learn v√† PySpark
- **B√°o c√°o**: `report/lab5.md`
- **Code**: `src/models/text_classifier.py`

### Lab 6: L√†m quen v·ªõi PyTorch
- **M√¥ t·∫£**: Th·ª±c h√†nh c∆° b·∫£n v·ªõi Tensor, autograd, v√† nn.Module
- **B√°o c√°o**: `report/lab6.md`
- **Notebook**: `notebook/pytorch_intro.ipynb`

### Lab 7: RNNs cho Text Classification
- **M√¥ t·∫£**: Ph√¢n lo·∫°i intent s·ª≠ d·ª•ng RNN tr√™n dataset HWU
- **B√°o c√°o**: `report/lab7.md`, `report/lab5_rnns_text_classification.pdf`
- **Notebook**: `notebook/rnns_text_classification.ipynb`

### Lab 8: RNN for POS Tagging
- **M√¥ t·∫£**: X√¢y d·ª±ng m√¥ h√¨nh BiLSTM cho POS tagging
- **B√°o c√°o**: `report/lab8.md`, `report/lab5_rnn_for_pos_tagging.pdf`
- **Notebook**: `notebook/lab5_rnn_pos_tagging.ipynb`

## C√†i ƒë·∫∑t v√† ch·∫°y

### Y√™u c·∫ßu
- Python 3.11+
- Java (cho Spark)
- Scala 2.12+ (cho Spark projects)

### C√†i ƒë·∫∑t dependencies
```bash
pip install -r requirements.txt
```

### Ch·∫°y tests
```bash
# Ch·∫°y test cho Lab 1-2
python -m test.main

# Ch·∫°y test cho Lab 2
python -m test.lab2_test

# Ch·∫°y test cho Lab 4
python test/Lab4_test.py

# Ch·∫°y test cho Lab 5
python test/lab5_test.py
```

## Datasets

C√°c dataset ƒë∆∞·ª£c s·ª≠ d·ª•ng:
- **UD English-EWT**: Universal Dependencies English Web Treebank
- **C4 Dataset**: Colossal Clean Crawled Corpus
- **HWU Dataset**: Home Assistant Understanding dataset
- **Sentiments Dataset**: T·∫≠p d·ªØ li·ªáu ph√¢n lo·∫°i c·∫£m x√∫c

Xem chi ti·∫øt trong `data/README.md`.

## B√°o c√°o

T·∫•t c·∫£ c√°c b√°o c√°o ƒë∆∞·ª£c l∆∞u trong th∆∞ m·ª•c `report/`:

### B√°o c√°o c√°c Lab
- `lab1-2.md`: B√°o c√°o Lab 1-2
- `lab2.md`: B√°o c√°o Lab 2
- `lab4.md`: B√°o c√°o Lab 4
- `lab5.md`: B√°o c√°o Lab 5
- `lab6.md`: B√°o c√°o Lab 6
- `lab7.md`: B√°o c√°o Lab 7
- `lab8.md`: B√°o c√°o Lab 8
- `lab5_rnns_text_classification.pdf`: PDF b√°o c√°o Lab 7
- `lab5_rnn_for_pos_tagging.pdf`: PDF b√°o c√°o Lab 8

### Nghi√™n c·ª©u b·ªï sung
- `tts_research.md`: Nghi√™n c·ª©u t·ªïng quan v·ªÅ Text To Speech (TTS) - bao g·ªìm c√°c ph∆∞∆°ng ph√°p tri·ªÉn khai, ∆∞u nh∆∞·ª£c ƒëi·ªÉm, v√† pipeline t·ªëi ∆∞u

## üîß C√¥ng ngh·ªá s·ª≠ d·ª•ng

- **Python**: scikit-learn, PyTorch, Gensim, PySpark
- **Scala**: Apache Spark MLlib
- **Frameworks**: TensorFlow, PyTorch
- **Tools**: Jupyter Notebook, Apache Spark

## üìÑ License

C√°c dataset v√† code tu√¢n theo license c·ªßa t·ª´ng ngu·ªìn t∆∞∆°ng ·ª©ng.

## üë§ T√°c gi·∫£

Repository n√†y ƒë∆∞·ª£c t·∫°o cho m·ª•c ƒë√≠ch h·ªçc t·∫≠p v√† nghi√™n c·ª©u.

